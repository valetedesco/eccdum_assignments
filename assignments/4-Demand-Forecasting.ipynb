{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "069b7111",
   "metadata": {},
   "source": [
    "# Notebook overview\n",
    "\n",
    "The objective of this notebook, is to learn how to transform a time-series problem (demand forecasting) into a tabular one.\n",
    "\n",
    "For this we will use the M5 competition dataset, large and popular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b932c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dask[dataframe] eccd_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807965c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from eccd_datasets import load_m5\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d679de9",
   "metadata": {},
   "source": [
    "# Preparing the dataset\n",
    "\n",
    "Since the dataset is quite large, it comes in three pieces: calendar events, sales and sell_prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6abafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_m5()\n",
    "datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c684bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar = datasets[\"calendar\"]\n",
    "df_calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0d221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = datasets[\"sales\"]\n",
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3d4b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices = datasets[\"sell_prices\"]\n",
    "df_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d26dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_id(id_: str, sales: pd.DataFrame, prices: pd.DataFrame, calendar: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts the dataframe associated with a single item id in long format.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = sales[sales[\"id\"] == id_].drop(columns=[\"id\"])\n",
    "    df = pd.melt(\n",
    "        df, \n",
    "        id_vars=[\n",
    "            \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"],\n",
    "        var_name = \"d\",\n",
    "        value_name = \"units_sold\"\n",
    "        \n",
    "    )\n",
    "    \n",
    "    df = df.merge(calendar, on=\"d\", how=\"left\") \n",
    "    df = df.merge(prices, on=[\"item_id\", \"store_id\", \"wm_yr_wk\"], how=\"left\")\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a0f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = \"HOBBIES_1_001_CA_1_validation\"\n",
    "df_id = get_data_from_id(ID, df_sales, df_prices, df_calendar)\n",
    "print(df_id.shape)\n",
    "df_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55956cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 4))\n",
    "\n",
    "ax.plot(df_id[\"units_sold\"])\n",
    "ax.set_xlabel(\"Days\")\n",
    "ax.set_ylabel(\"# Units sold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce64759",
   "metadata": {},
   "source": [
    "We can drop all the attributes that describe the price but don't change across rows since they will not provide useful informaton for training a model.\n",
    "\n",
    "Furthermore, there are many attributes that are redundant and can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc4d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = df_id.drop(columns=[\n",
    "    \"item_id\", \"dept_id\", \"state_id\", \"cat_id\", \"store_id\", \"d\", \"wm_yr_wk\",\n",
    "    \"weekday\", \"month\", \"year\", \"wday\"\n",
    "])\n",
    "df_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25245c31",
   "metadata": {},
   "source": [
    "We observe that for some events we don't have a price. We can assume that in those cases, the price is equal to the oldest price available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dce0478",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id[\"sell_price\"] = df_id[\"sell_price\"].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410502c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560d1e8c",
   "metadata": {},
   "source": [
    "Implement a function call build_temporal_features that takes `date_variable` which should be a pandas datetype and a `target` wich should be the column name to forecast to create creates several temporal features from it.\n",
    "    \n",
    "In particular, it should create the additional columns in the dataframe\n",
    "\n",
    "Asume that all variables are in the range [0, x])\n",
    "\n",
    "* `day_of_month` (0 - 30) -> **Assumen that all month has 31 days and the number of the first day is 0**\n",
    "* `month` (Jan = 0)\n",
    "* `day_of_week` (Monday=0, Sunday= 6)\n",
    "* `day_of_week_sin` \n",
    "* `day_of_week_cos`\n",
    "* `month_cos`\n",
    "* `month_sin`\n",
    "* `day_of_month_sin`\n",
    "* `day_of_month_cos`\n",
    "* `lag_1`\n",
    "* `lag_7`\n",
    "\n",
    "Remember to sort the dataframe using the data varaible with the most\n",
    "recent values in the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5abd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_temporal_features(date_variable: str, target: str, df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f61c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = build_temporal_features(\"date\", \"units_sold\", df_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8597964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b052f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.iloc[1019]\n",
    "assert np.allclose(row[\"day_of_week\"], 2)\n",
    "assert np.allclose(row[\"day_of_month\"], 12)\n",
    "assert np.allclose(row[\"month_sin\"], -0.866025)\n",
    "assert np.allclose(row[\"month_cos\"], 0.5)\n",
    "assert np.allclose(row[\"day_of_week_sin\"], 0.974928)\n",
    "assert np.allclose(row[\"day_of_week_cos\"], -0.222521)\n",
    "assert np.allclose(row[\"day_of_month_cos\"], -0.758758)\n",
    "assert np.allclose(row[\"lag_1\"], 1)\n",
    "\n",
    "answer_month = row[\"month\"]\n",
    "answer_month_sin = row[\"day_of_month_sin\"]\n",
    "answer_lag7 = row[\"lag_7\"]\n",
    "\n",
    "print(answer_month)\n",
    "print(answer_month_sin)\n",
    "print(answer_lag7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653db5b5",
   "metadata": {},
   "source": [
    "# Splitting the dataset\n",
    "\n",
    "Unlike normal problems with tabular data, we can't randomly split the data (since each row has a temporal component).\n",
    "\n",
    "For this we will manually split the dataset and keep the last 30 as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b077ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.pop(\"units_sold\")\n",
    "X = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be279fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X.iloc[:-30], y.iloc[:-30]\n",
    "X_test, y_test = X.iloc[-30:], y.iloc[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3558b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc38e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb458f4",
   "metadata": {},
   "source": [
    "# Training with a simple AR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4095e46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arima = ARIMA(y_train, order=(7, 1, 0))\n",
    "arima_res = arima.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de66b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = arima_res.forecast(steps=30)\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f378dce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_mean_squared_error(y_pred, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c14b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(y_pred.values, label=\"predicted\")\n",
    "ax.plot(y_test.values, label=\"original\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208aa321",
   "metadata": {},
   "source": [
    "# Training using ML with Tabular Data\n",
    "\n",
    "For simplicity we are going to use only the numerical features, without trying to properly encode the other ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a716b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.01,\n",
    "    'n_estimators': 450,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'seed': 200,\n",
    "    'num_threads': 1\n",
    "}\n",
    "\n",
    "model = lgb.LGBMRegressor(**params)\n",
    "\n",
    "model.fit(X_train.select_dtypes(include=[\"float\", \"int\"]), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf9a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test.select_dtypes(include=[\"float\", \"int\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2407a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_mean_squared_error(y_pred, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e911b717",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(y_pred, label=\"predicted\", marker=\"*\")\n",
    "ax.plot(y_test.values, label=\"original\", marker=\"o\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da24fed0",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "We showed how we can build a tabular dataset from a time-series and how we can use traditional techniques such as `Regression Trees` to train such model.\n",
    "\n",
    "In this example our analysis was quite basic and we kept only a minium number of variables.\n",
    "\n",
    "Furthermore, an approach that was not explored is to train several items at the same (which requires more computing power), which can further incrase the performance of the model."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
